{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (2.33.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from imageio) (1.24.4)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from imageio) (9.4.0)\n",
      "Requirement already satisfied: torchmetrics in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from torchmetrics) (1.24.4)\n",
      "Requirement already satisfied: torch>=1.8.1 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from torchmetrics) (2.1.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from torchmetrics) (0.10.0)\n",
      "Requirement already satisfied: packaging>=17.1 in c:\\users\\miles\\appdata\\roaming\\python\\python310\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (68.2.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from torch>=1.8.1->torchmetrics) (3.12.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from torch>=1.8.1->torchmetrics) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: ray[data,serve,train,tune] in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (8.1.7)\n",
      "Requirement already satisfied: filelock in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (3.12.4)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (4.19.1)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (1.0.6)\n",
      "Requirement already satisfied: packaging in c:\\users\\miles\\appdata\\roaming\\python\\python310\\site-packages (from ray[data,serve,train,tune]) (23.2)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (4.25.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (6.0.1)\n",
      "Requirement already satisfied: aiosignal in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (1.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (2.31.0)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (1.24.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (2.1.3)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (2.6.2.2)\n",
      "Requirement already satisfied: pyarrow<7.0.0,>=6.0.1 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (6.0.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (2023.10.0)\n",
      "Requirement already satisfied: starlette in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (0.27.0)\n",
      "Requirement already satisfied: aiohttp>=3.7 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (3.9.1)\n",
      "Requirement already satisfied: py-spy>=0.2.0 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (0.3.14)\n",
      "Requirement already satisfied: uvicorn[standard] in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (0.24.0.post1)\n",
      "Requirement already satisfied: watchfiles in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (0.21.0)\n",
      "Requirement already satisfied: aiohttp-cors in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (0.7.0)\n",
      "Requirement already satisfied: colorful in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (0.5.5)\n",
      "Requirement already satisfied: smart-open in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (6.4.0)\n",
      "Requirement already satisfied: aiorwlock in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (1.3.0)\n",
      "Requirement already satisfied: fastapi in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (0.104.1)\n",
      "Requirement already satisfied: gpustat>=1.0.0 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (1.1.1)\n",
      "Requirement already satisfied: pydantic<2 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (1.10.13)\n",
      "Requirement already satisfied: opencensus in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (0.11.3)\n",
      "Requirement already satisfied: virtualenv<20.21.1,>=20.0.24 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (20.21.0)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (0.17.1)\n",
      "Requirement already satisfied: grpcio>=1.42.0 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from ray[data,serve,train,tune]) (1.59.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from aiohttp>=3.7->ray[data,serve,train,tune]) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from aiohttp>=3.7->ray[data,serve,train,tune]) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from aiohttp>=3.7->ray[data,serve,train,tune]) (1.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from aiohttp>=3.7->ray[data,serve,train,tune]) (4.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from click>=7.0->ray[data,serve,train,tune]) (0.4.6)\n",
      "Requirement already satisfied: nvidia-ml-py>=11.450.129 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from gpustat>=1.0.0->ray[data,serve,train,tune]) (12.535.133)\n",
      "Requirement already satisfied: psutil>=5.6.0 in c:\\users\\miles\\appdata\\roaming\\python\\python310\\site-packages (from gpustat>=1.0.0->ray[data,serve,train,tune]) (5.9.6)\n",
      "Requirement already satisfied: blessed>=1.17.1 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from gpustat>=1.0.0->ray[data,serve,train,tune]) (1.20.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from pandas->ray[data,serve,train,tune]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from pandas->ray[data,serve,train,tune]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from pandas->ray[data,serve,train,tune]) (2023.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from pydantic<2->ray[data,serve,train,tune]) (4.8.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from virtualenv<20.21.1,>=20.0.24->ray[data,serve,train,tune]) (0.3.7)\n",
      "Requirement already satisfied: platformdirs<4,>=2.4 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from virtualenv<20.21.1,>=20.0.24->ray[data,serve,train,tune]) (3.10.0)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from fastapi->ray[data,serve,train,tune]) (3.7.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from jsonschema->ray[data,serve,train,tune]) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from jsonschema->ray[data,serve,train,tune]) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from jsonschema->ray[data,serve,train,tune]) (0.10.3)\n",
      "Requirement already satisfied: opencensus-context>=0.1.3 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from opencensus->ray[data,serve,train,tune]) (0.1.3)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from opencensus->ray[data,serve,train,tune]) (2.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from requests->ray[data,serve,train,tune]) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from requests->ray[data,serve,train,tune]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from requests->ray[data,serve,train,tune]) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from requests->ray[data,serve,train,tune]) (2023.7.22)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from uvicorn[standard]->ray[data,serve,train,tune]) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from uvicorn[standard]->ray[data,serve,train,tune]) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from uvicorn[standard]->ray[data,serve,train,tune]) (1.0.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from uvicorn[standard]->ray[data,serve,train,tune]) (12.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from anyio<4.0.0,>=3.7.1->fastapi->ray[data,serve,train,tune]) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from anyio<4.0.0,>=3.7.1->fastapi->ray[data,serve,train,tune]) (1.1.3)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[data,serve,train,tune]) (0.2.7)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[data,serve,train,tune]) (1.16.0)\n",
      "Requirement already satisfied: jinxed>=1.1.0 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[data,serve,train,tune]) (1.2.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (1.61.0)\n",
      "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (2.23.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (4.9)\n",
      "Requirement already satisfied: ansicon in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from jinxed>=1.1.0->blessed>=1.17.1->gpustat>=1.0.0->ray[data,serve,train,tune]) (1.89.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[data,serve,train,tune]) (0.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: requests in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.1.1 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from torchvision) (2.1.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from torch==2.1.1->torchvision) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from torch==2.1.1->torchvision) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from torch==2.1.1->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from torch==2.1.1->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from torch==2.1.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from torch==2.1.1->torchvision) (2023.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from requests->torchvision) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from requests->torchvision) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from jinja2->torch==2.1.1->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\miles\\miniconda3\\envs\\nyu-dl\\lib\\site-packages (from sympy->torch==2.1.1->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imageio\n",
    "!pip install torchmetrics\n",
    "!pip install -U ray[data,train,tune,serve]\n",
    "!pip install -U torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import imageio.v3 as iio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchmetrics \n",
    "import os \n",
    "from torch import nn, optim\n",
    "from torchvision.io import read_image\n",
    "from sys import getsizeof\n",
    "from torch.utils.data import random_split,Dataset,DataLoader \n",
    "from torchvision import transforms, tv_tensors\n",
    "from torchvision.transforms import v2\n",
    "import random \n",
    "import torch.nn.functional as F\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_location = \"./Project Data/Dataset_Student/train/\"\n",
    "val_location = \"./Project Data/Dataset_Student/val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Semantic_Segmentation_Dataset(Dataset):\n",
    "    def __init__(self, mask_list,input_transform = None,target_transform = None):\n",
    "        self.mask_list = mask_list\n",
    "        self.input_transform = input_transform \n",
    "        self.target_transform = target_transform \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mask_list)\n",
    "    \n",
    "\n",
    "    def transform(self, image,mask):\n",
    "        if self.input_transform:\n",
    "            image = self.input_transform(image)\n",
    "        if self.target_transform:\n",
    "            mask = self.target_transform(mask)\n",
    "\n",
    "        identical_transform = v2.Compose([\n",
    "            v2.ToImage(),\n",
    "            v2.RandomCrop(size=(160,240),padding=(40,60),padding_mode='edge'),\n",
    "            v2.RandomHorizontalFlip(p=.5),\n",
    "            v2.RandomVerticalFlip(p=.5),\n",
    "            v2.RandomRotation(degrees=45),\n",
    "        ])\n",
    "\n",
    "        new_img,new_msk = identical_transform((image,mask)\n",
    "                                      )\n",
    "        return new_img,new_msk\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.mask_list[idx][0]\n",
    "        target = self.mask_list[idx][1]\n",
    "\n",
    "        if self.input_transform:\n",
    "            image = self.input_transform(image)\n",
    "        if self.target_transform:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        image,target = self.transform(image,target)\n",
    "\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_video_mask(video_folder):\n",
    "    '''split_video_mask Creats a list of tuples (image,mask)\n",
    "\n",
    "    :param video_folder: directory to video folder\n",
    "    :type video_folder: path\n",
    "    :return: list of tuples of form (pytorch tensor, pytorch tensor) (size [3, 160, 240],[160, 240])\n",
    "    '''\n",
    "    directory = video_folder\n",
    "    \n",
    "    img_mask_dict = {}\n",
    "    list_of_segments = []\n",
    "\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".png\"):\n",
    "            index = str(os.path.basename(file)[6:-4])\n",
    "            img = tv_tensors.Image(PIL.Image.open(os.path.join(directory,file)))\n",
    "            img_mask_dict[index] = img.to(torch.get_default_dtype())\n",
    " \n",
    "\n",
    "        if filename.endswith(\".npy\"):\n",
    "            #print(os.path.join(directory, filename))\n",
    "            mask = torch.from_numpy(np.load(os.path.join(directory,file))).to(torch.get_default_dtype())\n",
    "            mask = tv_tensors.Image(mask)\n",
    "            \n",
    "\n",
    "    for key,val in img_mask_dict.items():\n",
    "        list_of_segments.append((val,tv_tensors.Image(mask[int(key)])))\n",
    "\n",
    "    \n",
    "    return list_of_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(video_folder):\n",
    "    train_folder = video_folder\n",
    "    \n",
    "    subdir_list = os.listdir(train_folder)\n",
    "    mask_list = []\n",
    "\n",
    "    for subdir in subdir_list:\n",
    "        train_mask_list = split_video_mask(os.path.join(train_folder,subdir))\n",
    "        mask_list = mask_list + train_mask_list\n",
    "\n",
    "\n",
    "    data_sample = random.sample(mask_list,400)\n",
    "    input_mean = torch.mean(torch.Tensor(data_sample[0][0]),dim=[1,2])\n",
    "    input_std = torch.std(torch.Tensor(data_sample[0][0]),dim=[1,2])\n",
    "\n",
    "\n",
    "    height = mask_list[0][0].shape[1]\n",
    "    width = mask_list[0][0].shape[2]\n",
    "\n",
    "    input_transform = v2.Normalize(input_mean,input_std)\n",
    "\n",
    "\n",
    "    ss_dataset = Semantic_Segmentation_Dataset(mask_list[:63], \n",
    "                                            input_transform=input_transform,\n",
    "                                            target_transform=None\n",
    "                                            )\n",
    "\n",
    "    generator = torch.Generator().manual_seed(10)\n",
    "\n",
    "    train_set, test_set = random_split(ss_dataset,[.7, .3],generator=generator)\n",
    "\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PracticeNet(nn.Module):\n",
    "    def __init__(self, chan_1=8):\n",
    "        super(PracticeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, chan_1, kernel_size=7,padding=3)\n",
    "        self.conv2 = nn.Conv2d(chan_1, 49, kernel_size=5,padding=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        return x.view(-1,49,160,240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_practice(hyperparameters, video_folder=None):\n",
    "    #net = PracticeNet(hyperparameters[\"chan_1\"])\n",
    "    net = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', weights=None)\n",
    "    net.classifier._modules['4'] = torch.nn.Conv2d(256, 49, kernel_size=(1, 1), stride=(1, 1))\n",
    "    optimizer = optim.Adam(net.parameters(),lr=hyperparameters[\"lr\"])\n",
    "    \n",
    "    if os.path.isfile(\"./practice_stop.pth\") and os.path.getsize(\"./practice_stop.pth\") > 0:\n",
    "        checkpoint = torch.load(\"./practice_stop.pth\")\n",
    "        net.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        running_loss = checkpoint['loss']\n",
    "        best_val_jac = checkpoint['best_val_jac']\n",
    "        print(\"Resuming training from epoch: \",start_epoch)\n",
    "    else: \n",
    "        best_val_jac = 0\n",
    "        start_epoch = 0 \n",
    "        running_loss = 0 \n",
    "\n",
    "    jaccard = torchmetrics.JaccardIndex(task=\"multiclass\", num_classes=49)\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = jaccard\n",
    "    \n",
    "    \n",
    "    train_subset, val_subset = load_data(video_folder)\n",
    "    height = train_subset[0][1].shape[0]\n",
    "    width = train_subset[0][1].shape[1]\n",
    "    print(\"data loaded\")\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_subset, batch_size=int(hyperparameters[\"batch_size\"]), shuffle=True, drop_last=True,\n",
    "    )\n",
    "    valloader = torch.utils.data.DataLoader(\n",
    "        val_subset, batch_size=len(val_subset), \n",
    "    )\n",
    "\n",
    "    for epoch in range(start_epoch,hyperparameters[\"max_epochs\"]):\n",
    "        print(epoch)\n",
    "        net.train()\n",
    "        batch_loss = 0\n",
    "        count = 1\n",
    "        for batch in trainloader:\n",
    "            count += 1\n",
    "            data = batch[0].to(device)\n",
    "            labels = batch[1].to(device).squeeze()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            predicted = torch.nn.functional.softmax(net(data)['out'],dim=1)\n",
    "            loss = jaccard(predicted,labels).requires_grad_(True)\n",
    "            batch_loss += batch_loss + loss.item()\n",
    "            #loss.requires_grad =  True\n",
    "            loss.backward()\n",
    "            optimizer.step\n",
    "            \n",
    "            torch.save({'epoch': epoch+1,\n",
    "            'model_state_dict': net.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': running_loss,\n",
    "            'best_val_jac':best_val_jac,\n",
    "            }, \"practice_stop.pth\")\n",
    "\n",
    "\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        batch_cnt = 1\n",
    "\n",
    "        for batch in valloader:\n",
    "            with torch.no_grad():\n",
    "                data = batch[0].to(device)\n",
    "                labels = batch[1].to(device).squeeze()\n",
    "\n",
    "      \n",
    "                predicted = F.softmax(net(data)['out'],dim=1)\n",
    "                predicted = torch.argmax(predicted,dim=1)       #(Shape N,H,W)\n",
    "     \n",
    "                loss = criterion(predicted, labels)\n",
    "                val_jac = 100 * jaccard(predicted,labels)\n",
    "                # Save the best model\n",
    "                if val_jac > best_val_jac:\n",
    "                    best_val_jac = val_jac\n",
    "                    torch.save({'epoch': epoch+1,\n",
    "                    'model_state_dict': net.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': running_loss,\n",
    "                    'best_val_jac':best_val_jac,\n",
    "                    }, \"practice_best.pth\")\n",
    "\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "                batch_size = predicted.shape[0]\n",
    "                correct = 0 \n",
    "                \n",
    "                for k in range(batch_size):\n",
    "                    for i in range(height):\n",
    "                        for j in range(width):\n",
    "                            if predicted[k][i][j].item() == labels[k][i][j].item():\n",
    "                                correct += 1  \n",
    "                    \n",
    "            val_jac = 100 * jaccard(predicted,labels)\n",
    "            print(f\"Epoch: {epoch + 1}, Validation Accuracy (Jaccard): {val_jac:.2f}%\")\n",
    "\n",
    "           \n",
    "            batch_cnt += 1\n",
    "            total = batch_cnt * height * width\n",
    "            print(\"epoch, pixel acc = \",100*correct/total)\n",
    "\n",
    "\n",
    "            if epoch == 5:\n",
    "                print(\"exiting at epoch \",epoch)\n",
    "                raise SystemExit(1)\n",
    "    print(running_loss)\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Miles/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n",
      "0\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "Epoch: 1, Validation Accuracy (Jaccard): 0.07%\n",
      "epoch, pixel acc =  11.875\n",
      "1\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "Epoch: 2, Validation Accuracy (Jaccard): 0.05%\n",
      "epoch, pixel acc =  5.0\n",
      "2\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "Epoch: 3, Validation Accuracy (Jaccard): 0.09%\n",
      "epoch, pixel acc =  3.75\n",
      "3\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "Epoch: 4, Validation Accuracy (Jaccard): 0.10%\n",
      "epoch, pixel acc =  5.3125\n",
      "4\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "Epoch: 5, Validation Accuracy (Jaccard): 0.05%\n",
      "epoch, pixel acc =  0.625\n",
      "5\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "torch.Size([2, 49, 160, 240])\n",
      "Epoch: 6, Validation Accuracy (Jaccard): 0.04%\n",
      "epoch, pixel acc =  1.25\n",
      "exiting at epoch  5\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Miles\\miniconda3\\envs\\NYU-DL\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "hyperparamters = {\"chan_1\":16,\"batch_size\":2,\"max_epochs\":20,\"lr\":0.001}\n",
    "data_dir = train_location\n",
    "train_practice(hyperparamters,video_folder=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Miles/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from epoch:  6\n",
      "data loaded\n",
      "6\n",
      "Epoch: 7, Validation Accuracy (Jaccard): 0.08%\n",
      "epoch, pixel acc =  8.4375\n",
      "7\n",
      "Epoch: 8, Validation Accuracy (Jaccard): 0.06%\n",
      "epoch, pixel acc =  2.1875\n",
      "8\n",
      "Epoch: 9, Validation Accuracy (Jaccard): 0.10%\n",
      "epoch, pixel acc =  5.0\n",
      "9\n",
      "Epoch: 10, Validation Accuracy (Jaccard): 0.08%\n",
      "epoch, pixel acc =  1.5625\n",
      "10\n",
      "Epoch: 11, Validation Accuracy (Jaccard): 0.05%\n",
      "epoch, pixel acc =  6.5625\n",
      "11\n",
      "Epoch: 12, Validation Accuracy (Jaccard): 0.10%\n",
      "epoch, pixel acc =  8.125\n",
      "12\n",
      "Epoch: 13, Validation Accuracy (Jaccard): 0.04%\n",
      "epoch, pixel acc =  3.4375\n",
      "13\n",
      "Epoch: 14, Validation Accuracy (Jaccard): 0.10%\n",
      "epoch, pixel acc =  6.875\n",
      "14\n",
      "Epoch: 15, Validation Accuracy (Jaccard): 0.05%\n",
      "epoch, pixel acc =  7.1875\n",
      "15\n",
      "Epoch: 16, Validation Accuracy (Jaccard): 0.06%\n",
      "epoch, pixel acc =  1.875\n",
      "16\n",
      "Epoch: 17, Validation Accuracy (Jaccard): 0.04%\n",
      "epoch, pixel acc =  1.25\n",
      "17\n",
      "Epoch: 18, Validation Accuracy (Jaccard): 0.07%\n",
      "epoch, pixel acc =  12.5\n",
      "18\n",
      "Epoch: 19, Validation Accuracy (Jaccard): 0.06%\n",
      "epoch, pixel acc =  5.625\n",
      "19\n",
      "Epoch: 20, Validation Accuracy (Jaccard): 0.06%\n",
      "epoch, pixel acc =  5.3125\n",
      "0\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train_practice(hyperparamters,video_folder=data_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NYU-DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
